{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and look at the content\n",
    "digits = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some of the images\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2705396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training and testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ff5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the shapes of the training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7280df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the logistic regression\n",
    "logisticRegr = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4a0d17",
   "metadata": {},
   "source": [
    "# inspect the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cfdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35492799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79515870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd7cd0",
   "metadata": {},
   "source": [
    "# Get the predictions and evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1225cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the accuracy both on the train and on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec87f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbefd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "# first implement one, \n",
    "\n",
    "#then use the library\n",
    "cm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa169494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the confusion matrix\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Pastel1')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "\n",
    "for x in np.arange(width):\n",
    "    for y in np.arange(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "plt.savefig('toy_Digits_ConfusionMatplotlibCodementor.png')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one image from the test set, print its label and output the predicted label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
